# ðŸ§© SprintÂ 4 â€” Entrenamiento y puesta en marcha del **Clasificador de CategorÃ­as**

> **Objetivo del sprint**â€¯â€¯âž¡ï¸â€¯Entrenar un modelo DistilBERT que reconozca la categorÃ­a municipal de una consulta ciudadana (6 clases) y exponerlo vÃ­a APIÂ FastAPI/Uvicorn para que el chatbot React pueda consumirlo.

---

## 1.Â Estructura de carpetas

```text
nlp-services/
â”œâ”€ data/
â”‚Â Â â”œâ”€ raw/               â†  train_v1.json  (dataset completo)
â”‚Â Â â””â”€ processed/         â†  train/val/test CSV generados
â”‚
â”œâ”€ scripts/              â†  ETL del dataset
â”‚Â Â â”œâ”€ validate_dataset.py      # valida contra JSONâ€‘Schema
â”‚Â Â â”œâ”€ train_schema.json        # esquema de validaciÃ³n
â”‚Â Â â”œâ”€ clean_text.py            # normaliza y exporta CSV
â”‚Â Â â””â”€ split_dataset.py         # 80â€¯/â€¯10â€¯/â€¯10 split
â”‚
â”œâ”€ nlp_service/
â”‚Â Â â”œâ”€ __init__.py
â”‚Â Â â”œâ”€ utils.py                 # mÃ©tricas F1 / accuracy
â”‚Â Â â”œâ”€ train.py                 # ENTRENAMIENTO (este sprint)
â”‚Â Â â”œâ”€ api.py                   # APIÂ FastAPI
â”‚Â Â â””â”€ models/
â”‚Â Â Â Â Â â””â”€ category_classifier/   # pesos + vocab + mÃ©tricas
â”‚
â””â”€ requirements.txt
```

---

## 2.Â PreparaciÃ³n del dataset (SprintÂ 2 &Â 3)

| Paso | DescripciÃ³n                                      | Comando                              |
| ---- | ------------------------------------------------ | ------------------------------------ |
| 1ï¸âƒ£  | Validar esquema                                  | `python scripts/validate_dataset.py` |
| 2ï¸âƒ£  | Limpiar texto (lower, quitar tildes, normalizar) | `python scripts/clean_text.py`       |
| 3ï¸âƒ£  | Split train/val/test 80â€‘10â€‘10                    | `python scripts/split_dataset.py`    |

Al terminar aparecen:

```text
data/processed/train.csv   (1327 filas)
data/processed/val.csv     (166 filas)
data/processed/test.csv    (166 filas)
```

---

## 3.Â Entorno de trabajo

```bash
# Crear venv (recomendado)
py -3.11 -m venv .venv
.venv\Scripts\activate      # PowerShell / CMD

# Dependencias (CPUâ€‘only)
pip install --no-cache-dir \
  torch==2.2.0+cpu -f https://download.pytorch.org/whl/torch_stable.html \
  transformers==4.41.1 \
  datasets==2.19.0 \
  accelerate>=0.21.0 \
  typer pandas scikit-learn fastapi uvicorn rich safetensors
```

> *NumPy quedÃ³ fijado aÂ **1.26.x** para evitar incompatibilidad conÂ datasetsÂ 2.19.*

---

## 4.Â Entrenamiento del modelo (DistilBERTÂ mâ€‘cased)

```bash
# Ejecutado desde nlp-services/
python -m nlp_service.train \
       --csv-dir data/processed \
       --out-dir nlp_service/models/category_classifier \
       --epochs 3 \
       --batch 8
```

### Puntos clave del script `train.py`

* **TokenizaciÃ³n** con `DistilBertTokenizerFast` + `DataCollatorWithPadding` (padding dinÃ¡mico).
* **TrainingArguments**: `evaluation_strategy="epoch"`, `save_strategy="epoch"`, `load_best_model_at_end=True`.
* MÃ©tricas personalizadas en `utils.py` (accuracy, F1Â macro/weighted).

#### Resultado final (CPUÂ i5â€‘13Âª gen Â· 16â€¯GB)

| MÃ©trica test  | Valor      |
| ------------- | ---------- |
| Accuracy      | **0.849**  |
| F1Â (macro)    | 0.855      |
| F1Â (weighted) | 0.849      |
| Crossâ€‘entropy | 0.54       |
| Training time | 5Â minÂ 23Â s |

Los pesos y vocabulario quedan en:
`nlp_service/models/category_classifier/`.

---

## 5.Â API de inferencia

```bash
uvicorn nlp_service.api:app --host 0.0.0.0 --port 8000
```

### Ejemplo de llamada

<details>
<summary>PowerShell (Invokeâ€‘RestMethod)</summary>

```powershell
Invoke-RestMethod -Method Post -Uri http://localhost:8000/predict `
                  -Body '{"text":"quiero renovar mi licencia de funcionamiento"}' `
                  -ContentType 'application/json'
```

</details>

<details>
<summary>cURL real (curl.exe / Bash)</summary>

```bash
curl.exe -X POST http://localhost:8000/predict \
         -H "Content-Type: application/json" \
         -d '{"text":"quiero renovar mi licencia de funcionamiento"}'
```

</details>

**Respuesta**

```json
{"categoria":"ACTIVIDAD ECONÃ“MICA Y PUBLICIDAD"}
```

---

## 6.Â Problemas resueltos en el sprint

| Error                                                        | Causa                                    | Fix                                                                  |
| ------------------------------------------------------------ | ---------------------------------------- | -------------------------------------------------------------------- |
| `ModuleNotFoundError: nlp_service`                           | Script ejecutado como file               | Ejecutar con `python -m` o usar imports relativos                    |
| `Type 16 arrow schema`                                       | Columns string sin remover               | `remove_columns(["category","subcategory"])`                         |
| `TrainingArguments unexpected keyword 'evaluation_strategy'` | Transformers antiguo / datasets 4.0 fake | Migrar a PythonÂ 3.11, instalar transformersÂ 4.41.1 + datasetsÂ 2.19.0 |
| `stack expects each tensor to be equal size`                 | Falta padding                            | `DataCollatorWithPadding`                                            |
| `No space left on device`                                    | Disco lleno instalando wheels            | `--no-cache-dir`, purgar cache, torchâ€‘cpu                            |

---

## 7.Â PrÃ³ximos pasos

1. **SprintÂ 5**Â â†’ entrenar subâ€‘clasificadores por categorÃ­a (`subcategory_<cat>`).
2. Dockerizar el servicio con `torch-cpu` y exponer en el VPS.
3. Integrar endpoint en React + flujo de voz.
4. Registrar preguntas rechazadas para retrain mensual.

---

### ðŸ”—Â Comando resumen

```bash
python -m nlp_service.train --csv-dir data/processed --out-dir nlp_service/models/category_classifier --epochs 3 --batch 8
```

Â¡SprintÂ 4 completado ðŸš€!  Ahora el chatbot puede detectar la categorÃ­a municipal de cada consulta con \~85â€¯% de precisiÃ³n.

con el modelo  BERT:d
{
  "eval_loss": 0.4953695237636566,
  "eval_accuracy": 0.8493975903614458,
  "eval_f1_macro": 0.8231022646116987,
  "eval_f1_weighted": 0.8479686941837432,
  "eval_runtime": 1.3283,
  "eval_samples_per_second": 124.975,
  "eval_steps_per_second": 8.281,
  "epoch": 6.0
}

python -m nlp_service.train --csv-dir data/processed --out-dir nlp_service/models/category_classifier --epochs 6 --batch 16 --model-name bert-base-multilingual-cased --lr 1e-5